# Model Selection Module ğŸš€

Bu modÃ¼l, makine Ã¶ÄŸrenmesi modellerini otomatik olarak deÄŸerlendiren ve en iyi performans gÃ¶steren modeli seÃ§en bir araÃ§tÄ±r. Regresyon, sÄ±nÄ±flandÄ±rma ve kÃ¼meleme problemleri iÃ§in Ã§eÅŸitli algoritmalar iÃ§erir. AyrÄ±ca, veri Ã¶n iÅŸleme ve keÅŸifsel veri analizi (EDA) iÃ§in kapsamlÄ± fonksiyonlar saÄŸlar.

## Ã–zellikler ğŸŒŸ

### Model SeÃ§ici (ModelSelector)

- **Ã‡oklu Problem Tipi DesteÄŸi**: Regresyon, sÄ±nÄ±flandÄ±rma ve kÃ¼meleme problemleri iÃ§in kullanÄ±labilir
- **GeniÅŸ Model Yelpazesi**: 
  - 14 regresyon algoritmasÄ±
  - 14 sÄ±nÄ±flandÄ±rma algoritmasÄ±
  - 5 kÃ¼meleme algoritmasÄ±
- **Ensemble Modeller**: Bagging, stacking, boosting ve voting yÃ¶ntemleri
- **Otomatik Model DeÄŸerlendirme**: TÃ¼m modelleri eÄŸitir ve performanslarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±r
- **En Ä°yi Model SeÃ§imi**: Performans metriklerine gÃ¶re otomatik olarak en iyi modeli seÃ§er

### Veri Ã–n Ä°ÅŸleyici (DataPreprocessor)

- **Eksik Veri Ä°ÅŸleme**: Ã‡eÅŸitli eksik veri doldurma yÃ¶ntemleri
- **AykÄ±rÄ± DeÄŸer Tespiti ve Ä°ÅŸleme**: AykÄ±rÄ± deÄŸerlerin tespiti ve dÃ¼zeltilmesi
- **Ã–zellik Ã–lÃ§eklendirme**: StandartlaÅŸtÄ±rma, normalleÅŸtirme ve robust Ã¶lÃ§eklendirme
- **Kategorik DeÄŸiÅŸken Kodlama**: Label encoding, one-hot encoding ve ordinal encoding
- **Ã–zellik SeÃ§imi**: Ã‡eÅŸitli Ã¶zellik seÃ§im yÃ¶ntemleri
- **EDA GÃ¶rselleÅŸtirmeleri**: Veri daÄŸÄ±lÄ±mlarÄ±nÄ± ve iliÅŸkilerini gÃ¶steren gÃ¶rselleÅŸtirmeler

## Kurulum âš™ï¸

1. Gereksinimleri yÃ¼kleyin:
```bash
pip install -r requirements.txt
```

2. ModÃ¼lÃ¼ projenize ekleyin:
```python
from model_selector import ModelSelector
from data_preprocessor import DataPreprocessor
```

## KullanÄ±m ğŸ“Š

### Temel KullanÄ±m
```python
# Model seÃ§ici oluÅŸtur
model_selector = ModelSelector(problem_type='regression')

# Veri Ã¶n iÅŸleyici oluÅŸtur
preprocessor = DataPreprocessor()

# Veriyi yÃ¼kle ve Ã¶n iÅŸle
X, y = preprocessor.load_and_preprocess('data.csv')

# Modelleri eÄŸit ve deÄŸerlendir
best_model = model_selector.select_best_model(X, y)
```

### Tam Ã–rnek KullanÄ±m
Daha kapsamlÄ± bir Ã¶rnek iÃ§in `example_usage.py` dosyasÄ±na bakabilirsiniz. Bu dosya, veri Ã¶n iÅŸleme ve model seÃ§me modÃ¼llerinin birlikte nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± gÃ¶sterir.

```python
# Kendi modÃ¼llerimizi import et
from data_preprocessor import DataPreprocessor
from model_selector import ModelSelector
from sklearn.datasets import fetch_california_housing

# California ev fiyatlarÄ± veri setini yÃ¼kle
housing = fetch_california_housing()
california_data = pd.DataFrame(housing.data, columns=housing.feature_names)
california_data['PRICE'] = housing.target

# Data preprocessing
preprocessor = DataPreprocessor(verbose=True)

# Ã–n iÅŸleme adÄ±mlarÄ±nÄ± tanÄ±mla
preprocessing_steps = {
    'handle_missing_values': {'method': 'mean'},
    'handle_outliers': {'method': 'clip', 'threshold': 1.5},
    'scale_features': {'method': 'standard'},
    'feature_selection': {'method': 'importance', 'k': 8}
}

# Veriyi iÅŸle
processed_data = preprocessor.fit_transform(
    data=california_data,
    target='PRICE',
    preprocessing_steps=preprocessing_steps
)

# Hedef deÄŸiÅŸkeni ayÄ±r
X = processed_data.drop(columns=['PRICE'])
y = processed_data['PRICE']

# Model seÃ§imi
model_selector = ModelSelector(problem_type='regression')

# Ensemble modelleri ekle
model_selector.add_ensemble_model('stacking')
model_selector.add_ensemble_model('voting')

# Modelleri eÄŸit
model_selector.fit(X, y)

# En iyi modeli al
best_model_info = model_selector.get_best_model()
print(f"En iyi regresyon modeli: {best_model_info['model_name']}")
print(f"R2 skoru: {best_model_info['score']:.4f}")
```

## Test DosyalarÄ± ğŸ§ª

Proje, farklÄ± problem tipleri iÃ§in test dosyalarÄ± iÃ§erir:

### Regresyon Testi (test_regression.py)

California Housing veri seti kullanarak regresyon modellerini test eder.

```python
from sklearn.datasets import fetch_california_housing
from sklearn.preprocessing import StandardScaler
from model_selector import ModelSelector

# California Housing veri setini yÃ¼kle
housing = fetch_california_housing()
X = housing.data
y = housing.target

# Veriyi Ã¶lÃ§eklendir
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Regresyon modellerini test et
ms_reg = ModelSelector('regression')

# Modelleri eÄŸit ve deÄŸerlendir
ms_reg.fit(X_scaled, y, test_size=0.3, random_state=42)

# En iyi modeli gÃ¶ster
best_model_info = ms_reg.get_best_model()
print(f"Model: {best_model_info['model_name']}")
print(f"RÂ² Skoru: {best_model_info['score']:.4f}")
print("\nParametreler:")
for param, value in best_model_info['parameters'].items():
    print(f"  {param}: {value}")
```

### SÄ±nÄ±flandÄ±rma Testi (test_classification.py)

Iris veri seti kullanarak sÄ±nÄ±flandÄ±rma modellerini test eder.

```python
from sklearn.datasets import load_iris
from model_selector import ModelSelector

# Iris veri setini yÃ¼kle
iris = load_iris()
X = iris.data
y = iris.target
feature_names = iris.feature_names
target_names = iris.target_names

# SÄ±nÄ±flandÄ±rma modellerini test et
ms_cls = ModelSelector('classification')

# Modelleri eÄŸit ve deÄŸerlendir
ms_cls.fit(X, y, test_size=0.3, random_state=42)

# En iyi modeli gÃ¶ster
best_model_info = ms_cls.get_best_model()
print(f"Model: {best_model_info['model_name']}")
print(f"DoÄŸruluk Skoru: {best_model_info['score']:.4f}")
print("\nParametreler:")
for param, value in best_model_info['parameters'].items():
    print(f"  {param}: {value}")
```

### KÃ¼meleme Testi (test_clustering.py)

Yapay veri seti oluÅŸturarak kÃ¼meleme modellerini test eder.

```python
from sklearn.datasets import make_blobs
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from model_selector import ModelSelector

# Yapay kÃ¼meleme veri seti oluÅŸtur
X, y = make_blobs(n_samples=500, 
                 n_features=2, 
                 centers=4, 
                 cluster_std=1.0,
                 random_state=42)

# Veriyi Ã¶lÃ§eklendir
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# KÃ¼meleme modellerini test et
ms_clust = ModelSelector('clustering')

# Modelleri eÄŸit ve deÄŸerlendir
ms_clust.fit(X_scaled, None, test_size=0.3, random_state=42)

# SonuÃ§larÄ± gÃ¶ster
results = ms_clust.get_results()

# Silhouette skorlarÄ±nÄ± hesapla ve gÃ¶ster
for name, result in results.items():
    if 'error' in result:
        continue
    
    model = result['model']
    
    # KÃ¼meleme yap
    if hasattr(model, 'predict'):
        labels = model.predict(X_scaled)
    else:
        labels = model.fit_predict(X_scaled)
    
    # Silhouette skorunu hesapla
    n_labels = len(np.unique(labels))
    if n_labels > 1 and n_labels < len(X_scaled):
        score = silhouette_score(X_scaled, labels)
        print(f"{name}: Silhouette Skoru: {score:.4f}")
```

Testleri Ã§alÄ±ÅŸtÄ±rmak iÃ§in:
```bash
python test_regression.py
python test_classification.py
python test_clustering.py
```

## Proje YapÄ±sÄ± ğŸ“‚
```
model_selection_module/
â”œâ”€â”€ data_preprocessor.py    # Veri Ã¶n iÅŸleme modÃ¼lÃ¼
â”œâ”€â”€ model_selector.py       # Model seÃ§me modÃ¼lÃ¼
â”œâ”€â”€ example_usage.py        # Ã–rnek kullanÄ±m
â”œâ”€â”€ test_regression.py      # Regresyon testleri
â”œâ”€â”€ test_classification.py  # SÄ±nÄ±flandÄ±rma testleri
â”œâ”€â”€ test_clustering.py      # KÃ¼meleme testleri
â”œâ”€â”€ requirements.txt         # Gereksinimler
â””â”€â”€ README.md               # Bu dosya
```

## KatkÄ±da Bulunma ğŸ¤

KatkÄ±da bulunmak isterseniz:
1. Bu repo'yu fork edin
2. Yeni bir branch oluÅŸturun (`git checkout -b feature/awesome-feature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add some awesome feature'`)
4. Branch'inizi pushlayÄ±n (`git push origin feature/awesome-feature`)
5. Bir Pull Request aÃ§Ä±n

## Lisans ğŸ“œ
Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r - detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.
